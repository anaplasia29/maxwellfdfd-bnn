{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.layers import Average\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.signal import find_peaks\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 300\n",
    "activation = 'relu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss():\n",
    "    def __init__(self, loss_functions):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.loss_function_array = loss_functions.split(',')\n",
    "        print(self.loss_function_array)\n",
    "\n",
    "    def tf_diff_axis_1(self, a):\n",
    "        return a[:, 1:] - a[:, :-1]\n",
    "\n",
    "    def custom_loss(self, y_true, y_pred):\n",
    "        loss = 0\n",
    "        y_true_diff = self.tf_diff_axis_1(y_true)\n",
    "        y_pred_diff = self.tf_diff_axis_1(y_pred)\n",
    "        threshold_value = 0\n",
    "        y_true_diff_binary = K.cast(K.greater(y_true_diff, threshold_value), K.floatx())\n",
    "        y_pred_diff_binary = K.cast(K.greater(y_pred_diff, threshold_value), K.floatx())\n",
    "        if 'rmse' in self.loss_function_array:\n",
    "            loss = loss + K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "        if 'diff_rmse' in self.loss_function_array:\n",
    "            loss = loss + K.sqrt(K.mean(K.square(y_pred_diff - y_true_diff)))\n",
    "\n",
    "        if 'diff_ce' in self.loss_function_array:\n",
    "            loss = loss + losses.binary_crossentropy(y_true_diff, y_pred_diff)\n",
    "\n",
    "        if 'diff_bce' in self.loss_function_array:\n",
    "            loss = loss + losses.binary_crossentropy(y_true_diff_binary, y_pred_diff_binary)\n",
    "\n",
    "        return loss\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "def normalized_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square((y_pred - y_true) / 2600 / (y_true / 2600)), axis=-1))\n",
    "\n",
    "def ensemble(models, model_input):\n",
    "    outputs = [model(model_input) for model in models]\n",
    "    y = Average()(outputs)\n",
    "    model = Model(model_input, y, name='ensemble')\n",
    "    return model\n",
    "\n",
    "def compress_image(prev_image):\n",
    "    height = prev_image.shape[0] // 10\n",
    "    width = prev_image.shape[1] // 10\n",
    "    new_image = np.zeros((height, width), dtype=\"uint8\")\n",
    "    for i in range(0, height):\n",
    "        for j in range(0, width):\n",
    "            new_image[i, j] = prev_image[10*i, 10*j]\n",
    "    return new_image\n",
    "\n",
    "def ensembleModels(models, model_input):\n",
    "    # collect outputs of models in a list\n",
    "    yModels = [model(model_input) for model in models]\n",
    "    # averaging outputs\n",
    "    yAvg = Average(yModels)\n",
    "    # build model from same input and avg output\n",
    "    modelEns = Model(inputs=model_input, outputs=yAvg, name='ensemble')\n",
    "\n",
    "    return modelEns\n",
    "\n",
    "def tf_diff(a):\n",
    "    return a[1:] - a[:-1]\n",
    "\n",
    "\n",
    "def tf_diff_axis_1(a):\n",
    "    return a[:, 1:] - a[:, :-1]\n",
    "\n",
    "def image_trim(image, x=8, y=8):\n",
    "    print(image.shape)\n",
    "    images = []\n",
    "    width = image.shape[1] // x\n",
    "    height = image.shape[0] // y\n",
    "    print(width, height)\n",
    "    for i in range(0, x):\n",
    "        for j in range(0, y):\n",
    "            trimmed_image = image[j*height:j*height+height, i*width:i*width + width]\n",
    "            resized_image = cv2.resize(trimmed_image, None, fx=5, fy=5, interpolation=cv2.INTER_AREA)\n",
    "            cv2.imwrite('./data_test/image_from_gan/' + str(j) + '_' + str(i) + '.tiff', resized_image)\n",
    "            resized_image //= 255\n",
    "            images.append(resized_image)\n",
    "    return images\n",
    "\n",
    "def tic():\n",
    "    import time\n",
    "    global startTime_for_tictoc\n",
    "    startTime_for_tictoc = time.time()\n",
    "\n",
    "def toc():\n",
    "    import time\n",
    "    if 'startTime_for_tictoc' in globals():\n",
    "        runningTime = time.time() - startTime_for_tictoc\n",
    "        toc_ = \"Elapsed time is \" + str(runningTime) + \" seconds.\"\n",
    "        print(toc_)\n",
    "        return runningTime\n",
    "    else:\n",
    "        toc_ = \"Toc: start time not set\"\n",
    "        print(toc_)\n",
    "        return toc_\n",
    "\n",
    "\n",
    "def rescale(arr, std, mean):\n",
    "    arr = arr * std\n",
    "    arr = arr + mean\n",
    "\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "MODEL_SHAPE_TYPE = 'rect'\n",
    "\n",
    "## TEST\n",
    "DATAPATH = os.path.join('data', 'test')\n",
    "DATASETS = [\n",
    "    'binary_new_test_501',\n",
    "    'binary_new_test_1501',\n",
    "    'binary_rl_fix_1014',\n",
    "    'binary_rl_fix_1015',\n",
    "    'binary_rl_fix_test_1002',\n",
    "    'binary_rl_fix_test_1003',\n",
    "    'binary_rl_fix_test_1004',\n",
    "    'binary_rl_fix_test_1005',\n",
    "    'binary_test_1101',\n",
    "]\n",
    "\n",
    "model_names = [\n",
    "    'RMSE',\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "model_name_details = [\n",
    "    # 'cnn_128_5/rmse_rect_1',\n",
    "    f'cnn_128_{epochs}_{activation}/rmse_rect_1',\n",
    "    # f'cnn_128_{epochs}_relu/rmse_rect_1',\n",
    "    # f'cnn_128_{epochs}_elu/rmse_rect_1',\n",
    "    # f'cnn_128_{epochs}_sigmoid/rmse_rect_1',\n",
    "    # 'cnn_128_1000/rmse_rect_1',\n",
    "]\n",
    "\n",
    "colors=[\n",
    "    'green', 'skyblue', 'red',\n",
    "]\n",
    "\n",
    "model_folder_path = 'models'\n",
    "is_mean_std = False\n",
    "\n",
    "if MODEL_SHAPE_TYPE == 'rect':\n",
    "    img_rows, img_cols, channels = 100, 200, 1\n",
    "else:\n",
    "    img_rows, img_cols, channels = 200, 200, 1\n",
    "\n",
    "img_rows_compressed = img_rows // 10\n",
    "img_cols_compressed = img_cols // 10\n",
    "lowest_RMSE = 999\n",
    "lowest_RMSE_id = 0\n",
    "\n",
    "lowest_RMSE_DIFF_RMSE = 999\n",
    "lowset_RMSE_DIFF_RMSE_ID = 0\n",
    "\n",
    "lowset_local_RMSE = 999\n",
    "lowset_local_RMSE_id = 0\n",
    "\n",
    "lowest_POLY_RMSE = 999\n",
    "lowest_POLY_RMSE_ID = 0\n",
    "model_name = './'\n",
    "\n",
    "x_test = []\n",
    "x_test_compressed = []\n",
    "y_test = []\n",
    "y_test_compressed = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loading....\n",
      "Data Loading... Finished.\n"
     ]
    }
   ],
   "source": [
    "print('Data Loading....')\n",
    "\n",
    "# load dataset\n",
    "for i, data in enumerate(DATASETS):\n",
    "\n",
    "    dataframe = pd.read_csv('./{}/{}.csv'.format(DATAPATH, data), delim_whitespace=False, header=None)\n",
    "    dataset = dataframe.values\n",
    "    # split into input (X) and output (Y) variables\n",
    "    fileNames = dataset[:, 0]\n",
    "    y_test.extend(dataset[:, 1:25])\n",
    "    for idx, file in enumerate(fileNames):\n",
    "\n",
    "        try:\n",
    "            image = Image.open(os.path.join(DATAPATH, data, '{}.tiff'.format(int(file))))\n",
    "            image = np.array(image, dtype=np.uint8)\n",
    "        except (TypeError, FileNotFoundError) as te:\n",
    "\n",
    "            image = Image.open(os.path.join(DATAPATH, data, '{}.tiff'.format(idx + 1)))\n",
    "            # image = cv2.imread('{}/{}/{}.tiff'.format(DATAPATH, data, idx + 1), 0)\n",
    "\n",
    "            image = np.array(image, dtype=np.uint8)\n",
    "        # image //= 255\n",
    "        # print(image)\n",
    "\n",
    "        compressed_image = compress_image(image)\n",
    "\n",
    "        if MODEL_SHAPE_TYPE.startswith('rect'):\n",
    "            x_test.append(image)\n",
    "            x_test_compressed.append(compressed_image)\n",
    "        else:\n",
    "            v_flipped_image = np.flip(image, 0)\n",
    "            square_image = np.vstack([image, v_flipped_image])\n",
    "            x_test.append(square_image)\n",
    "\n",
    "            v_flipped_image_compressed = np.flip(compressed_image, 0)\n",
    "            square_image_compressed = np.vstack([compressed_image, v_flipped_image_compressed])\n",
    "            x_test_compressed.append(square_image_compressed)\n",
    "\n",
    "\n",
    "print('Data Loading... Finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array(x_test)\n",
    "x_test_compressed = np.array(x_test_compressed)\n",
    "y_test = np.array(y_test)\n",
    "y_test = np.true_divide(y_test, 2767.1)\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_test = x_test.reshape(x_test.shape[0], channels, img_rows, img_cols)\n",
    "    y_test = y_test.reshape(y_test.shape[0], channels, img_rows, img_cols)\n",
    "    x_test_compressed = x_test_compressed.reshape(x_test.shape[0], channels * img_rows_compressed * img_cols_compressed)\n",
    "    # y_test_compressed = y_test.reshape(y_test.shape[0], channels * img_rows_compressed * img_cols_compressed)\n",
    "    input_shape = (channels, img_rows, img_cols)\n",
    "    input_shape_compressed = channels*img_rows_compressed*img_cols_compressed\n",
    "else:\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, channels)\n",
    "    x_test_compressed = x_test_compressed.reshape(x_test_compressed.shape[0], channels*img_rows_compressed*img_cols_compressed)\n",
    "    # y_test_compressed = y_test.reshape(y_test.shape[0], channels*img_rows_compressed*img_cols_compressed)\n",
    "    input_shape = (img_rows, img_cols, channels)\n",
    "    input_shape_compressed = channels * img_rows_compressed * img_cols_compressed\n",
    "\n",
    "result = dict()\n",
    "result['real'] = x_test\n",
    "x_axis = range(400, 1600, 50)\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(14, 7))\n",
    "# ax.plot(x_axis, y_test, label='real', color='black')\n",
    "MODEL_JSON_PATH = ''\n",
    "MODEL_H5_PATH = ''\n",
    "myeongjo = 'NanumMyeongjo'\n",
    "\n",
    "mask_array = np.ones_like(y_test, np.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(y_test)):\n",
    "    peaks_positive, _ = find_peaks(y_test[j], height=0)\n",
    "    peaks_negative, _ = find_peaks(1 - y_test[j], height=0)\n",
    "    mask = np.ones(len(y_test[j]), np.bool)\n",
    "    mask[peaks_positive] = 0\n",
    "    mask[peaks_negative] = 0\n",
    "    mask_array[j][mask] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_runningTime = dict()\n",
    "result_r2 = dict()\n",
    "result_r2_local_minmax = dict()\n",
    "result_rmse = dict()\n",
    "result_rmse2 = dict()\n",
    "result_diff_rmse = dict()\n",
    "result_rmse_add_diff_rmse = dict()\n",
    "result_poly = dict()\n",
    "rmse_for_boxplot = dict()\n",
    "rmse_local_for_boxplot = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn_128_300_relu/rmse_rect_1\n",
      "Loaded model from disk\n",
      "Elapsed time is 10.151084423065186 seconds.\n",
      "running time: {'cnn_128_300_relu_rmse_rect_1': 10.151084423065186}\n",
      "rmse:  {'cnn_128_300_relu_rmse_rect_1': 0.10890681482428285}\n",
      "rmse local minmax:  {'cnn_128_300_relu_rmse_rect_1': 0.12008500377720453}\n",
      "r2:  {'cnn_128_300_relu_rmse_rect_1': 0.5507346254542471}\n",
      "r2-local:  {'cnn_128_300_relu_rmse_rect_1': 0.6399284104762248}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_list = []\n",
    "for i, model_name_detail in enumerate(model_name_details):\n",
    "    print(model_name_detail)\n",
    "    parsed_model_name = model_name_detail.split('/')[0]\n",
    "    runningTime = 0\n",
    "    if model_name_detail.startswith('cnn') or model_name_detail.startswith('nn'):\n",
    "        parsed_model_name = model_name_detail.split('/')[0] + '_' + model_name_detail.split('/')[1]\n",
    "        MODEL_JSON_PATH = '{}/{}.json'.format(model_folder_path, model_name_detail)\n",
    "        MODEL_H5_PATH = '{}/{}.h5'.format(model_folder_path, model_name_detail)\n",
    "        # load json and create model\n",
    "        json_file = open(MODEL_JSON_PATH, 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        loaded_model = model_from_json(loaded_model_json)\n",
    "        # load weights into new model\n",
    "        loaded_model.load_weights(MODEL_H5_PATH)\n",
    "        print(\"Loaded model from disk\")\n",
    "\n",
    "        loaded_GPR = joblib.load(f'./models/GPR_{epochs}_{activation}.pkl')\n",
    "\n",
    "        if model_name_detail.startswith('cnn'):\n",
    "            tic()\n",
    "            # y_predict = loaded_model.predict(x_test)\n",
    "            y_predict = loaded_model.predict(x_test)\n",
    "            y_predict = loaded_GPR.predict(y_predict)\n",
    "        else:\n",
    "            x_test_nn = x_test.reshape(x_test.shape[0], img_rows * img_cols * channels)\n",
    "            tic()\n",
    "            y_predict = loaded_model.predict(x_test_nn)\n",
    "        runningTime = toc()\n",
    "\n",
    "    else:\n",
    "        MODEL_PATH = '{}/{}/{}.joblib'.format(model_folder_path, model_name, model_name_detail)\n",
    "        loaded_model = joblib.load(MODEL_PATH)\n",
    "        tic()\n",
    "        y_predict = loaded_model.predict(x_test_compressed)\n",
    "        runningTime = toc()\n",
    "        # corr = np.corrcoef(y_test_compressed, y_predict)[0, 1]\n",
    "        # rmse = root_mean_squared_error(y_test_compressed, y_predict)\n",
    "\n",
    "    if is_mean_std == True:\n",
    "        MEAN = 0.5052\n",
    "        STD = 0.2104\n",
    "        y_predict = rescale(y_predict, MEAN, STD)\n",
    "\n",
    "\n",
    "    # corr = np.corrcoef(y_test, y_predict)[0, 1]\n",
    "    r2 = r2_score(y_test, y_predict)\n",
    "\n",
    "    meanSquaredError = mean_squared_error(y_test, y_predict)\n",
    "    rmse = sqrt(meanSquaredError)\n",
    "\n",
    "    rmse_all = []\n",
    "    count = 0\n",
    "\n",
    "    message = 'r2:{0:.4f}, RMSE:{1:.4f}'.format(r2, rmse)\n",
    "\n",
    "    rmse_for_boxplot[parsed_model_name] = rmse_all\n",
    "    y_test_for_local_minmax = y_test[mask_array]\n",
    "    y_predict_for_local_minmax = y_predict[mask_array]\n",
    "\n",
    "    y_test_for_local_minmax_inverse = y_test[~mask_array]\n",
    "    y_predict_for_local_minmax_inverse = y_predict[~mask_array]\n",
    "\n",
    "    rmse2 = sqrt(mean_squared_error(y_test_for_local_minmax, y_predict_for_local_minmax))\n",
    "    r2_local_minmax = r2_score(y_test_for_local_minmax, y_predict_for_local_minmax)\n",
    "    result_rmse2[parsed_model_name] = rmse2\n",
    "    result_r2[parsed_model_name] = r2\n",
    "    result_r2_local_minmax[parsed_model_name] = r2_local_minmax\n",
    "    result_rmse[parsed_model_name] = rmse\n",
    "    result_runningTime[parsed_model_name] = runningTime\n",
    "\n",
    "    y_test_diff = tf_diff_axis_1(y_test)\n",
    "    y_predict_diff = tf_diff_axis_1(y_predict)\n",
    "    mse_diff = mean_squared_error(y_test_diff, y_predict_diff)\n",
    "    rmse_diff = sqrt(mse_diff)\n",
    "    result_diff_rmse[parsed_model_name] = rmse_diff\n",
    "\n",
    "    result_rmse_add_diff_rmse[parsed_model_name] = rmse_diff + rmse\n",
    "\n",
    "    plt.scatter(y_predict_for_local_minmax_inverse, y_test_for_local_minmax_inverse, s=3, alpha=0.3, label='all', marker='+')\n",
    "    plt.scatter(y_predict_for_local_minmax, y_test_for_local_minmax, s=2, alpha=0.3, label='local_minmax', marker='.')\n",
    "    # x_margin = -0.05\n",
    "    x_margin = 0\n",
    "    plt.text(x_margin, 1, 'R² = %0.4f' % r2)\n",
    "    plt.text(x_margin, 0.95, 'RMSE = %0.4f' % rmse)\n",
    "    plt.text(x_margin, 0.9, 'local minmax R² = %0.4f' % r2_local_minmax)\n",
    "    plt.text(x_margin, 0.85, 'local minmax RMSE = %0.4f' % rmse2)\n",
    "    plt.xlabel('Predictions')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.savefig(\"{}/scatter_alpha/{}_all.png\".format('result', parsed_model_name))\n",
    "    plt.clf()\n",
    "\n",
    "print('running time:', result_runningTime)\n",
    "print('rmse: ', result_rmse)\n",
    "print('rmse local minmax: ', result_rmse2)\n",
    "print('r2: ', result_r2)\n",
    "print('r2-local: ', result_r2_local_minmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
