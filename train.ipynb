{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import losses\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = 'elu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss:\n",
    "    def __init__(self, _loss_function):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.loss_function_array = _loss_function.split(',')\n",
    "\n",
    "    def tf_diff_axis_1(self, a):\n",
    "        return a[:, 1:] - a[:, :-1]\n",
    "\n",
    "    def tf_minmax_axis_1(self, a):\n",
    "        b = self.tf_diff_axis_1(a)\n",
    "        sign = K.sign(b)\n",
    "        abs_sign = tf.abs(self.tf_diff_axis_1(sign))\n",
    "        mask_array = K.greater(abs_sign, 0)\n",
    "\n",
    "        result = tf.where(mask_array, a[:, 1:-1], tf.zeros_like(a[:, 1:-1]))\n",
    "\n",
    "        return result\n",
    "\n",
    "    def custom_loss(self, y_true, y_pred):\n",
    "        loss = 0\n",
    "        y_true_diff = self.tf_diff_axis_1(y_true)\n",
    "        y_pred_diff = self.tf_diff_axis_1(y_pred)\n",
    "        threshold_value = 0\n",
    "        y_true_diff_binary = K.cast(K.greater(y_true_diff, threshold_value), K.floatx())\n",
    "        y_pred_diff_binary = K.cast(K.greater(y_pred_diff, threshold_value), K.floatx())\n",
    "        y_true_minmax = self.tf_minmax_axis_1(y_true)\n",
    "        y_pred_minmax = self.tf_minmax_axis_1(y_pred)\n",
    "\n",
    "        if 'mse' in self.loss_function_array:\n",
    "            loss = loss + K.mean(K.square(y_pred - y_true))\n",
    "\n",
    "        if 'diff_mse' in self.loss_function_array:\n",
    "            loss = loss + K.mean(K.square(y_pred_diff - y_true_diff))\n",
    "\n",
    "        if 'rmse' in self.loss_function_array:\n",
    "            loss = loss + K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "        if 'diff_rmse' in self.loss_function_array:\n",
    "            loss = loss + K.sqrt(K.mean(K.square(y_pred_diff - y_true_diff)))\n",
    "\n",
    "        if 'diff_ce' in self.loss_function_array:\n",
    "            loss = loss + losses.binary_crossentropy(y_true_diff, y_pred_diff)\n",
    "\n",
    "        if 'diff_bce' in self.loss_function_array:\n",
    "            loss = loss + losses.binary_crossentropy(y_true_diff_binary, y_pred_diff_binary)\n",
    "\n",
    "        if 'diff_rmse_minmax' in self.loss_function_array:\n",
    "            loss = loss + K.sqrt(K.mean(K.square(y_pred_minmax - y_true_minmax)))\n",
    "\n",
    "        if 'diff_poly' in self.loss_function_array:\n",
    "            x = np.arange(24)\n",
    "            loss = loss + np.sum(\n",
    "                (np.polyval(np.polyfit(x, y_pred, 3)) - np.polyval(np.polyfit(x, y_true, 3))) ** 2\n",
    "            )\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tic():\n",
    "    import time\n",
    "    global startTime_for_tictoc\n",
    "    startTime_for_tictoc = time.time()\n",
    "\n",
    "def toc():\n",
    "    import time\n",
    "    if 'startTime_for_tictoc' in globals():\n",
    "        runningTime = time.time() - startTime_for_tictoc\n",
    "        toc_ = \"Elapsed time is \" + str(runningTime) + \" seconds.\"\n",
    "        print(toc_)\n",
    "        return runningTime\n",
    "    else:\n",
    "        toc_ = \"Toc: start time not set\"\n",
    "        print(toc_)\n",
    "        return toc_\n",
    "\n",
    "def scale(arr, std, mean):\n",
    "    arr -= mean\n",
    "    arr /= (std + 1e-7)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def rescale(arr, std, mean):\n",
    "    arr = arr * std\n",
    "    arr = arr + mean\n",
    "\n",
    "    return arr\n",
    "\n",
    "\n",
    "def compress_image(prev_image, n):\n",
    "    height = prev_image.shape[0] // n\n",
    "    width = prev_image.shape[1] // n\n",
    "    new_image = np.zeros((height, width), dtype=\"uint8\")\n",
    "    for i in range(0, height):\n",
    "        for j in range(0, width):\n",
    "            new_image[i, j] = prev_image[n * i, n * j]\n",
    "    return new_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_type, model_input_shape, loss_function):\n",
    "    if model_type.startswith('cnn'):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(16, kernel_size=(3, 3), padding='same', input_shape=model_input_shape, use_bias=False))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Conv2D(32, kernel_size=(3, 3), padding='same', use_bias=False))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Conv2D(32, kernel_size=(3, 3), padding='same', use_bias=False))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Conv2D(32, kernel_size=(3, 3), padding='same', use_bias=False))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1024, activation='relu'))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Dense(24, activation=activation))\n",
    "        model.compile(loss=loss_function, optimizer=Adam(lr=0.0005), metrics=['accuracy'])\n",
    "    elif model_type.startswith('rf'):\n",
    "        regr = RandomForestRegressor(n_estimators=100, max_depth=30, random_state=2)\n",
    "        return regr\n",
    "    elif model_type.startswith('svm'):\n",
    "        regr = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "        return regr\n",
    "    elif model_type.startswith('lasso'):\n",
    "        regr = Lasso()\n",
    "        return regr\n",
    "    elif model_type.startswith('lr'):\n",
    "        regr = LinearRegression()\n",
    "        return regr\n",
    "    elif model_type.startswith('ridge'):\n",
    "        regr = Ridge()\n",
    "        return regr\n",
    "    elif model_type.startswith('mlp'):\n",
    "        regr = MLPRegressor(solver='lbfgs', alpha=1e-5,\n",
    "                            hidden_layer_sizes=(20, 10), random_state=1)\n",
    "        return regr\n",
    "    elif model_type.startswith('knn'):\n",
    "        regr = KNeighborsRegressor()\n",
    "        return regr\n",
    "    elif model_type.startswith('elasticnet'):\n",
    "        regr = ElasticNet(random_state=0)\n",
    "        return regr\n",
    "    elif model_type.startswith('extratree'):\n",
    "        regr = ExtraTreesRegressor(n_estimators=10,\n",
    "                                   max_features=32,  # Out of 20000\n",
    "                                   random_state=0)\n",
    "        return regr\n",
    "    elif model_type.startswith('dt'):\n",
    "        regr = DecisionTreeRegressor(max_depth=5)\n",
    "        return regr\n",
    "    elif model_type.startswith('gbr'):\n",
    "        regr = MultiOutputRegressor(GradientBoostingRegressor(n_estimators=100, max_depth=5))\n",
    "        return regr\n",
    "    elif model_type.startswith('ada'):\n",
    "        regr = MultiOutputRegressor(AdaBoostRegressor(n_estimators=300))\n",
    "        return regr\n",
    "    else:\n",
    "        model = Sequential()\n",
    "        model.add(Dense(512, activation='relu', input_dim=model_input_shape))\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "        model.add(Dense(24, activation='sigmoid'))\n",
    "        model.compile(loss=loss_function, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAIN\n",
    "DATAPATH_TRAIN = os.path.join('data', 'train')\n",
    "DATASETS_TRAIN = [\n",
    "    'binary_501',\n",
    "    'binary_502',\n",
    "    'binary_503',\n",
    "    'binary_504',\n",
    "    'binary_505',\n",
    "    'binary_506',\n",
    "    'binary_507',\n",
    "    'binary_508',\n",
    "    'binary_509',\n",
    "    'binary_510',\n",
    "    'binary_511',\n",
    "    'binary_512',\n",
    "    'binary_1001',\n",
    "    'binary_1002',\n",
    "    'binary_1003',\n",
    "    'binary_rl_fix_501',\n",
    "    'binary_rl_fix_502',\n",
    "    'binary_rl_fix_503',\n",
    "    'binary_rl_fix_504',\n",
    "    'binary_rl_fix_505',\n",
    "    'binary_rl_fix_506',\n",
    "    'binary_rl_fix_507',\n",
    "    'binary_rl_fix_508',\n",
    "    'binary_rl_fix_509',\n",
    "    'binary_rl_fix_510',\n",
    "    'binary_rl_fix_511',\n",
    "    'binary_rl_fix_512',\n",
    "    'binary_rl_fix_513',\n",
    "    'binary_rl_fix_514',\n",
    "    'binary_rl_fix_515',\n",
    "    'binary_rl_fix_516',\n",
    "    'binary_rl_fix_517',\n",
    "    'binary_rl_fix_518',\n",
    "    'binary_rl_fix_519',\n",
    "    'binary_rl_fix_520',\n",
    "    'binary_rl_fix_1001',\n",
    "    'binary_rl_fix_1002',\n",
    "    'binary_rl_fix_1003',\n",
    "    'binary_rl_fix_1004',\n",
    "    'binary_rl_fix_1005',\n",
    "    'binary_rl_fix_1006',\n",
    "    'binary_rl_fix_1007',\n",
    "    'binary_rl_fix_1008',\n",
    "]\n",
    "\n",
    "## VALIDATION\n",
    "DATAPATH_VALID = './data/valid'\n",
    "DATASETS_VALID = [\n",
    "    'binary_1004',\n",
    "    'binary_test_1001',\n",
    "    'binary_test_1002',\n",
    "    'binary_rl_fix_1009',\n",
    "    'binary_rl_fix_1010',\n",
    "    'binary_rl_fix_1011',\n",
    "    'binary_rl_fix_1012',\n",
    "    'binary_rl_fix_1013',\n",
    "    'binary_rl_fix_test_1001',\n",
    "]\n",
    "\n",
    "## TEST\n",
    "DATAPATH_TEST = './data/test'\n",
    "DATASETS_TEST = [\n",
    "    'binary_new_test_501',\n",
    "    'binary_new_test_1501',\n",
    "    'binary_rl_fix_1014',\n",
    "    'binary_rl_fix_1015',\n",
    "    'binary_rl_fix_test_1002',\n",
    "    'binary_rl_fix_test_1003',\n",
    "    'binary_rl_fix_test_1004',\n",
    "    'binary_rl_fix_test_1005',\n",
    "    'binary_test_1101',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-d', '--data_type'], dest='data_type', nargs=None, const=None, default='train', type=None, choices=None, help='Select data type.. (train, valid, test)', metavar=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-m\", \"--model\", help=\"Select model type.\", default=\"cnn\")\n",
    "parser.add_argument(\"-s\", \"--shape\", help=\"Select input image shape. (rectangle or square?)\", default='rect')\n",
    "parser.add_argument(\"-l\", \"--loss_function\", help=\"Select loss functions.. (rmse,diff_rmse,diff_ce)\",\n",
    "                    default='rmse')\n",
    "parser.add_argument(\"-e\", \"--epochs\", help=\"Set epochs\", default=300)\n",
    "parser.add_argument(\"-b\", \"--batch_size\", help=\"Set batch size\", default=128)\n",
    "parser.add_argument(\"-n\", \"--is_normalized\", help=\"Set is Normalized\", action='store_true')\n",
    "parser.add_argument(\"-d\", \"--data_type\", help=\"Select data type.. (train, valid, test)\",\n",
    "                    default='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(args=[])\n",
    "model_name = args.model\n",
    "batch_size = int(args.batch_size)\n",
    "epochs = int(args.epochs)\n",
    "loss_functions = args.loss_function\n",
    "input_shape_type = args.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = DATAPATH_TRAIN\n",
    "DATASETS = DATASETS_TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_shape_type.startswith('rect'):\n",
    "    img_rows, img_cols, channels = 100, 200, 1\n",
    "else:\n",
    "    img_rows, img_cols, channels = 200, 200, 1\n",
    "\n",
    "if model_name.startswith('cnn') is False and model_name.startswith('nn') is False:\n",
    "    img_rows = img_rows // 10\n",
    "    img_cols = img_cols // 10\n",
    "\n",
    "x_train = []\n",
    "y_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/43 [00:00<00:05,  8.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loading... Train dataset Start.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:08<00:00,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loading... Train dataset Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Data Loading... Train dataset Start.')\n",
    "\n",
    "# load Train dataset\n",
    "for data in tqdm(DATASETS):\n",
    "    dataframe = pd.read_csv(os.path.join(DATAPATH, '{}.csv'.format(data)), delim_whitespace=False, header=None)\n",
    "    dataset = dataframe.values\n",
    "\n",
    "    # split into input (X) and output (Y) variables\n",
    "    fileNames = dataset[:, 0]\n",
    "    y_train.extend(dataset[:, 1:25])\n",
    "    for idx, file in enumerate(fileNames):\n",
    "\n",
    "        try:\n",
    "            image = Image.open(os.path.join(DATAPATH, data, '{}.tiff'.format(int(file))))\n",
    "            image = np.array(image, dtype=np.uint8)\n",
    "        except (TypeError, FileNotFoundError) as te:\n",
    "            image = Image.open(os.path.join(DATAPATH, data, '{}.tiff'.format(idx + 1)))\n",
    "            try:\n",
    "                image = np.array(image, dtype=np.uint8)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        if model_name.startswith('cnn') is False and model_name.startswith('nn') is False:\n",
    "            image = compress_image(image, 10)\n",
    "\n",
    "        if model_name.startswith('cnn_small'):\n",
    "            image = compress_image(image, 5)\n",
    "\n",
    "        if input_shape_type.startswith('rect'):\n",
    "            x_train.append(image)\n",
    "        else:\n",
    "            v_flipped_image = np.flip(image, 0)\n",
    "            square_image = np.vstack([image, v_flipped_image])\n",
    "            x_train.append(square_image)\n",
    "\n",
    "print('Data Loading... Train dataset Finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loading... Validation dataset Start.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:03<00:00,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loading... Validation dataset Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Data Loading... Validation dataset Start.')\n",
    "\n",
    "DATAPATH = DATAPATH_VALID\n",
    "DATASETS = DATASETS_VALID\n",
    "\n",
    "x_validation = []\n",
    "y_validation = []\n",
    "for data in tqdm(DATASETS):\n",
    "    dataframe = pd.read_csv(os.path.join(DATAPATH, '{}.csv'.format(data)), delim_whitespace=False, header=None)\n",
    "    dataset = dataframe.values\n",
    "\n",
    "    # split into input (X) and output (Y) variables\n",
    "    fileNames = dataset[:, 0]\n",
    "    y_validation.extend(dataset[:, 1:25])\n",
    "    for idx, file in enumerate(fileNames):\n",
    "\n",
    "        try:\n",
    "            image = Image.open(os.path.join(DATAPATH, data, '{}.tiff'.format(int(file))))\n",
    "            image = np.array(image, dtype=np.uint8)\n",
    "        except (TypeError, FileNotFoundError) as te:\n",
    "            image = Image.open(os.path.join(DATAPATH, data, '{}.tiff'.format(idx + 1)))\n",
    "            try:\n",
    "                image = np.array(image, dtype=np.uint8)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        if model_name.startswith('cnn') is False and model_name.startswith('nn') is False:\n",
    "            image = compress_image(image, 10)\n",
    "\n",
    "        if model_name.startswith('cnn_small'):\n",
    "            image = compress_image(image, 5)\n",
    "\n",
    "        if input_shape_type.startswith('rect'):\n",
    "            x_validation.append(image)\n",
    "        else:\n",
    "            v_flipped_image = np.flip(image, 0)\n",
    "            square_image = np.vstack([image, v_flipped_image])\n",
    "            x_validation.append(square_image)\n",
    "\n",
    "print('Data Loading... Validation dataset Finished.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "y_train = np.true_divide(y_train, 2767.1)\n",
    "\n",
    "x_validation = np.array(x_validation)\n",
    "y_validation = np.array(y_validation)\n",
    "y_validation = np.true_divide(y_validation, 2767.1)\n",
    "\n",
    "if args.is_normalized:\n",
    "    print('y_train mean : ', y_train.mean(), np.std(y_train))\n",
    "    MEAN = 0.5052\n",
    "    STD = 0.2104\n",
    "    y_train = scale(y_train, MEAN, STD)\n",
    "    y_validaton = scale(y_validation, MEAN, STD)\n",
    "\n",
    "if model_name.startswith('cnn'):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x_train = x_train.reshape(x_train.shape[0], channels, img_rows, img_cols)\n",
    "        y_train = y_train.reshape(y_train.shape[0], channels, img_rows, img_cols)\n",
    "\n",
    "        x_validation = x_validation.reshape(x_validation.shape[0], channels, img_rows, img_cols)\n",
    "        y_validation = y_validation.reshape(y_validation.shape[0], channels, img_rows, img_cols)\n",
    "        input_shape = (channels, img_rows, img_cols)\n",
    "    else:\n",
    "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, channels)\n",
    "        x_validation = x_validation.reshape(x_validation.shape[0], img_rows, img_cols, channels)\n",
    "        input_shape = (img_rows, img_cols, channels)\n",
    "else:\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x_train = x_train.reshape(x_train.shape[0], channels * img_rows * img_cols)\n",
    "        y_train = y_train.reshape(y_train.shape[0], channels * img_rows * img_cols)\n",
    "        x_validation = x_validation.reshape(x_validation.shape[0], channels * img_rows * img_cols)\n",
    "        y_validation = y_validation.reshape(y_validation.shape[0], channels * img_rows * img_cols)\n",
    "        input_shape = channels * img_rows * img_cols\n",
    "    else:\n",
    "        x_train = x_train.reshape(x_train.shape[0], img_rows * img_cols * channels)\n",
    "        x_validation = x_validation.reshape(x_validation.shape[0], img_rows * img_cols * channels)\n",
    "        input_shape = channels * img_rows * img_cols\n",
    "\n",
    "# for DEBUG\n",
    "# print('x shape:', x_train.shape)\n",
    "# print('y shape:', y_train.shape)\n",
    "# print(x_train.shape[0], 'train samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "  1/211 [..............................] - ETA: 0s - loss: 0.5673 - accuracy: 0.0078WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0061s vs `on_train_batch_end` time: 0.0098s). Check your callbacks.\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.1455 - accuracy: 0.1347 - val_loss: 0.0902 - val_accuracy: 0.1807\n",
      "Epoch 2/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.1061 - accuracy: 0.1791 - val_loss: 0.0801 - val_accuracy: 0.2249\n",
      "Epoch 3/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0980 - accuracy: 0.1931 - val_loss: 0.0761 - val_accuracy: 0.2390\n",
      "Epoch 4/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0940 - accuracy: 0.2093 - val_loss: 0.0727 - val_accuracy: 0.2534\n",
      "Epoch 5/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0921 - accuracy: 0.2124 - val_loss: 0.0712 - val_accuracy: 0.2684\n",
      "Epoch 6/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0898 - accuracy: 0.2234 - val_loss: 0.0776 - val_accuracy: 0.2687\n",
      "Epoch 7/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0881 - accuracy: 0.2332 - val_loss: 0.0695 - val_accuracy: 0.2399\n",
      "Epoch 8/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0871 - accuracy: 0.2401 - val_loss: 0.0685 - val_accuracy: 0.2834\n",
      "Epoch 9/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0857 - accuracy: 0.2473 - val_loss: 0.0692 - val_accuracy: 0.3101\n",
      "Epoch 10/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0845 - accuracy: 0.2533 - val_loss: 0.0675 - val_accuracy: 0.2988\n",
      "Epoch 11/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0837 - accuracy: 0.2604 - val_loss: 0.0673 - val_accuracy: 0.2787\n",
      "Epoch 12/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0821 - accuracy: 0.2673 - val_loss: 0.0671 - val_accuracy: 0.2800\n",
      "Epoch 13/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0810 - accuracy: 0.2770 - val_loss: 0.0658 - val_accuracy: 0.3081\n",
      "Epoch 14/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0805 - accuracy: 0.2789 - val_loss: 0.0666 - val_accuracy: 0.3201\n",
      "Epoch 15/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0791 - accuracy: 0.2896 - val_loss: 0.0676 - val_accuracy: 0.3180\n",
      "Epoch 16/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0779 - accuracy: 0.2910 - val_loss: 0.0670 - val_accuracy: 0.3344\n",
      "Epoch 17/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0771 - accuracy: 0.2986 - val_loss: 0.0645 - val_accuracy: 0.3204\n",
      "Epoch 18/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0761 - accuracy: 0.3057 - val_loss: 0.0648 - val_accuracy: 0.3106\n",
      "Epoch 19/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0750 - accuracy: 0.3031 - val_loss: 0.0682 - val_accuracy: 0.3171\n",
      "Epoch 20/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0742 - accuracy: 0.3097 - val_loss: 0.0661 - val_accuracy: 0.3318\n",
      "Epoch 21/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0729 - accuracy: 0.3100 - val_loss: 0.0657 - val_accuracy: 0.3420\n",
      "Epoch 22/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0722 - accuracy: 0.3132 - val_loss: 0.0635 - val_accuracy: 0.3322\n",
      "Epoch 23/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0714 - accuracy: 0.3206 - val_loss: 0.0653 - val_accuracy: 0.3379\n",
      "Epoch 24/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0703 - accuracy: 0.3247 - val_loss: 0.0645 - val_accuracy: 0.3314\n",
      "Epoch 25/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0695 - accuracy: 0.3218 - val_loss: 0.0645 - val_accuracy: 0.3037\n",
      "Epoch 26/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0687 - accuracy: 0.3239 - val_loss: 0.0638 - val_accuracy: 0.3214\n",
      "Epoch 27/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0677 - accuracy: 0.3277 - val_loss: 0.0639 - val_accuracy: 0.3326\n",
      "Epoch 28/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0668 - accuracy: 0.3324 - val_loss: 0.0643 - val_accuracy: 0.3240\n",
      "Epoch 29/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0665 - accuracy: 0.3296 - val_loss: 0.0640 - val_accuracy: 0.3137\n",
      "Epoch 30/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0661 - accuracy: 0.3356 - val_loss: 0.0628 - val_accuracy: 0.3276\n",
      "Epoch 31/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0652 - accuracy: 0.3376 - val_loss: 0.0644 - val_accuracy: 0.3328\n",
      "Epoch 32/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0646 - accuracy: 0.3353 - val_loss: 0.0628 - val_accuracy: 0.3290\n",
      "Epoch 33/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0640 - accuracy: 0.3362 - val_loss: 0.0643 - val_accuracy: 0.3274\n",
      "Epoch 34/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0635 - accuracy: 0.3361 - val_loss: 0.0634 - val_accuracy: 0.3473\n",
      "Epoch 35/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0634 - accuracy: 0.3423 - val_loss: 0.0646 - val_accuracy: 0.3380\n",
      "Epoch 36/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0625 - accuracy: 0.3429 - val_loss: 0.0633 - val_accuracy: 0.3190\n",
      "Epoch 37/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0625 - accuracy: 0.3416 - val_loss: 0.0639 - val_accuracy: 0.3417\n",
      "Epoch 38/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0616 - accuracy: 0.3407 - val_loss: 0.0631 - val_accuracy: 0.3346\n",
      "Epoch 39/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0614 - accuracy: 0.3495 - val_loss: 0.0626 - val_accuracy: 0.3422\n",
      "Epoch 40/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0607 - accuracy: 0.3486 - val_loss: 0.0623 - val_accuracy: 0.3361\n",
      "Epoch 41/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0607 - accuracy: 0.3508 - val_loss: 0.0619 - val_accuracy: 0.3432\n",
      "Epoch 42/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0600 - accuracy: 0.3494 - val_loss: 0.0624 - val_accuracy: 0.3401\n",
      "Epoch 43/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0600 - accuracy: 0.3501 - val_loss: 0.0623 - val_accuracy: 0.3216\n",
      "Epoch 44/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0595 - accuracy: 0.3482 - val_loss: 0.0632 - val_accuracy: 0.3269\n",
      "Epoch 45/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0596 - accuracy: 0.3489 - val_loss: 0.0617 - val_accuracy: 0.3206\n",
      "Epoch 46/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0590 - accuracy: 0.3526 - val_loss: 0.0615 - val_accuracy: 0.3381\n",
      "Epoch 47/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0588 - accuracy: 0.3534 - val_loss: 0.0619 - val_accuracy: 0.3371\n",
      "Epoch 48/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0583 - accuracy: 0.3544 - val_loss: 0.0620 - val_accuracy: 0.3442\n",
      "Epoch 49/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0580 - accuracy: 0.3620 - val_loss: 0.0616 - val_accuracy: 0.3433\n",
      "Epoch 50/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0582 - accuracy: 0.3547 - val_loss: 0.0616 - val_accuracy: 0.3422\n",
      "Epoch 51/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0577 - accuracy: 0.3566 - val_loss: 0.0617 - val_accuracy: 0.3533\n",
      "Epoch 52/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0580 - accuracy: 0.3569 - val_loss: 0.0621 - val_accuracy: 0.3302\n",
      "Epoch 53/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0572 - accuracy: 0.3558 - val_loss: 0.0615 - val_accuracy: 0.3327\n",
      "Epoch 54/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0572 - accuracy: 0.3603 - val_loss: 0.0615 - val_accuracy: 0.3489\n",
      "Epoch 55/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0569 - accuracy: 0.3606 - val_loss: 0.0625 - val_accuracy: 0.3277\n",
      "Epoch 56/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0567 - accuracy: 0.3599 - val_loss: 0.0617 - val_accuracy: 0.3436\n",
      "Epoch 57/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0563 - accuracy: 0.3643 - val_loss: 0.0626 - val_accuracy: 0.3198\n",
      "Epoch 58/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0561 - accuracy: 0.3606 - val_loss: 0.0612 - val_accuracy: 0.3334\n",
      "Epoch 59/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0561 - accuracy: 0.3633 - val_loss: 0.0608 - val_accuracy: 0.3392\n",
      "Epoch 60/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0561 - accuracy: 0.3593 - val_loss: 0.0622 - val_accuracy: 0.3489\n",
      "Epoch 61/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0561 - accuracy: 0.3707 - val_loss: 0.0610 - val_accuracy: 0.3510\n",
      "Epoch 62/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0558 - accuracy: 0.3645 - val_loss: 0.0611 - val_accuracy: 0.3247\n",
      "Epoch 63/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0556 - accuracy: 0.3639 - val_loss: 0.0608 - val_accuracy: 0.3312\n",
      "Epoch 64/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0553 - accuracy: 0.3646 - val_loss: 0.0608 - val_accuracy: 0.3560\n",
      "Epoch 65/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0553 - accuracy: 0.3716 - val_loss: 0.0611 - val_accuracy: 0.3410\n",
      "Epoch 66/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0552 - accuracy: 0.3688 - val_loss: 0.0609 - val_accuracy: 0.3451\n",
      "Epoch 67/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0550 - accuracy: 0.3636 - val_loss: 0.0602 - val_accuracy: 0.3382\n",
      "Epoch 68/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0552 - accuracy: 0.3669 - val_loss: 0.0619 - val_accuracy: 0.3389\n",
      "Epoch 69/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0548 - accuracy: 0.3704 - val_loss: 0.0607 - val_accuracy: 0.3497\n",
      "Epoch 70/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0545 - accuracy: 0.3683 - val_loss: 0.0603 - val_accuracy: 0.3369\n",
      "Epoch 71/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0545 - accuracy: 0.3673 - val_loss: 0.0613 - val_accuracy: 0.3366\n",
      "Epoch 72/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0543 - accuracy: 0.3730 - val_loss: 0.0605 - val_accuracy: 0.3431\n",
      "Epoch 73/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0544 - accuracy: 0.3725 - val_loss: 0.0607 - val_accuracy: 0.3450\n",
      "Epoch 74/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0541 - accuracy: 0.3737 - val_loss: 0.0614 - val_accuracy: 0.3350\n",
      "Epoch 75/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0540 - accuracy: 0.3691 - val_loss: 0.0605 - val_accuracy: 0.3210\n",
      "Epoch 76/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0539 - accuracy: 0.3695 - val_loss: 0.0602 - val_accuracy: 0.3388\n",
      "Epoch 77/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0538 - accuracy: 0.3736 - val_loss: 0.0606 - val_accuracy: 0.3348\n",
      "Epoch 78/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0536 - accuracy: 0.3782 - val_loss: 0.0603 - val_accuracy: 0.3426\n",
      "Epoch 79/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0538 - accuracy: 0.3751 - val_loss: 0.0601 - val_accuracy: 0.3429\n",
      "Epoch 80/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0534 - accuracy: 0.3792 - val_loss: 0.0605 - val_accuracy: 0.3369\n",
      "Epoch 81/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0534 - accuracy: 0.3771 - val_loss: 0.0610 - val_accuracy: 0.3437\n",
      "Epoch 82/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0532 - accuracy: 0.3752 - val_loss: 0.0604 - val_accuracy: 0.3406\n",
      "Epoch 83/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0531 - accuracy: 0.3792 - val_loss: 0.0611 - val_accuracy: 0.3402\n",
      "Epoch 84/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0534 - accuracy: 0.3765 - val_loss: 0.0607 - val_accuracy: 0.3348\n",
      "Epoch 85/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0532 - accuracy: 0.3824 - val_loss: 0.0606 - val_accuracy: 0.3236\n",
      "Epoch 86/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0535 - accuracy: 0.3766 - val_loss: 0.0606 - val_accuracy: 0.3367\n",
      "Epoch 87/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0527 - accuracy: 0.3780 - val_loss: 0.0609 - val_accuracy: 0.3418\n",
      "Epoch 88/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0529 - accuracy: 0.3796 - val_loss: 0.0598 - val_accuracy: 0.3478\n",
      "Epoch 89/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0530 - accuracy: 0.3810 - val_loss: 0.0605 - val_accuracy: 0.3293\n",
      "Epoch 90/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0527 - accuracy: 0.3824 - val_loss: 0.0604 - val_accuracy: 0.3531\n",
      "Epoch 91/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0528 - accuracy: 0.3803 - val_loss: 0.0612 - val_accuracy: 0.3464\n",
      "Epoch 92/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0525 - accuracy: 0.3840 - val_loss: 0.0604 - val_accuracy: 0.3486\n",
      "Epoch 93/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0522 - accuracy: 0.3807 - val_loss: 0.0596 - val_accuracy: 0.3502\n",
      "Epoch 94/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0525 - accuracy: 0.3850 - val_loss: 0.0608 - val_accuracy: 0.3483\n",
      "Epoch 95/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0525 - accuracy: 0.3825 - val_loss: 0.0597 - val_accuracy: 0.3472\n",
      "Epoch 96/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0524 - accuracy: 0.3827 - val_loss: 0.0604 - val_accuracy: 0.3449\n",
      "Epoch 97/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0522 - accuracy: 0.3864 - val_loss: 0.0598 - val_accuracy: 0.3521\n",
      "Epoch 98/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0520 - accuracy: 0.3816 - val_loss: 0.0600 - val_accuracy: 0.3404\n",
      "Epoch 99/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0519 - accuracy: 0.3916 - val_loss: 0.0594 - val_accuracy: 0.3516\n",
      "Epoch 100/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0516 - accuracy: 0.3853 - val_loss: 0.0599 - val_accuracy: 0.3476\n",
      "Epoch 101/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0519 - accuracy: 0.3865 - val_loss: 0.0597 - val_accuracy: 0.3390\n",
      "Epoch 102/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0520 - accuracy: 0.3849 - val_loss: 0.0601 - val_accuracy: 0.3372\n",
      "Epoch 103/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0515 - accuracy: 0.3851 - val_loss: 0.0609 - val_accuracy: 0.3371\n",
      "Epoch 104/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0519 - accuracy: 0.3888 - val_loss: 0.0596 - val_accuracy: 0.3483\n",
      "Epoch 105/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0515 - accuracy: 0.3880 - val_loss: 0.0598 - val_accuracy: 0.3388\n",
      "Epoch 106/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0514 - accuracy: 0.3854 - val_loss: 0.0596 - val_accuracy: 0.3344\n",
      "Epoch 107/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0515 - accuracy: 0.3886 - val_loss: 0.0597 - val_accuracy: 0.3567\n",
      "Epoch 108/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0514 - accuracy: 0.3863 - val_loss: 0.0592 - val_accuracy: 0.3507\n",
      "Epoch 109/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0515 - accuracy: 0.3872 - val_loss: 0.0610 - val_accuracy: 0.3462\n",
      "Epoch 110/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0511 - accuracy: 0.3889 - val_loss: 0.0597 - val_accuracy: 0.3541\n",
      "Epoch 111/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0511 - accuracy: 0.3885 - val_loss: 0.0596 - val_accuracy: 0.3492\n",
      "Epoch 112/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0512 - accuracy: 0.3869 - val_loss: 0.0597 - val_accuracy: 0.3533\n",
      "Epoch 113/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0510 - accuracy: 0.3879 - val_loss: 0.0603 - val_accuracy: 0.3642\n",
      "Epoch 114/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0512 - accuracy: 0.3926 - val_loss: 0.0602 - val_accuracy: 0.3483\n",
      "Epoch 115/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0510 - accuracy: 0.3910 - val_loss: 0.0599 - val_accuracy: 0.3506\n",
      "Epoch 116/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0510 - accuracy: 0.3893 - val_loss: 0.0614 - val_accuracy: 0.3301\n",
      "Epoch 117/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0508 - accuracy: 0.3892 - val_loss: 0.0607 - val_accuracy: 0.3543\n",
      "Epoch 118/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0509 - accuracy: 0.3879 - val_loss: 0.0605 - val_accuracy: 0.3449\n",
      "Epoch 119/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0508 - accuracy: 0.3912 - val_loss: 0.0592 - val_accuracy: 0.3509\n",
      "Epoch 120/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0507 - accuracy: 0.3909 - val_loss: 0.0595 - val_accuracy: 0.3389\n",
      "Epoch 121/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0509 - accuracy: 0.3937 - val_loss: 0.0599 - val_accuracy: 0.3422\n",
      "Epoch 122/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0506 - accuracy: 0.3909 - val_loss: 0.0596 - val_accuracy: 0.3532\n",
      "Epoch 123/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0507 - accuracy: 0.3905 - val_loss: 0.0598 - val_accuracy: 0.3503\n",
      "Epoch 124/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0504 - accuracy: 0.3913 - val_loss: 0.0599 - val_accuracy: 0.3479\n",
      "Epoch 125/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0508 - accuracy: 0.3929 - val_loss: 0.0596 - val_accuracy: 0.3506\n",
      "Epoch 126/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0503 - accuracy: 0.3946 - val_loss: 0.0591 - val_accuracy: 0.3509\n",
      "Epoch 127/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0505 - accuracy: 0.3937 - val_loss: 0.0594 - val_accuracy: 0.3469\n",
      "Epoch 128/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0503 - accuracy: 0.3932 - val_loss: 0.0602 - val_accuracy: 0.3644\n",
      "Epoch 129/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0502 - accuracy: 0.3976 - val_loss: 0.0604 - val_accuracy: 0.3506\n",
      "Epoch 130/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0505 - accuracy: 0.3954 - val_loss: 0.0596 - val_accuracy: 0.3582\n",
      "Epoch 131/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0505 - accuracy: 0.3943 - val_loss: 0.0604 - val_accuracy: 0.3353\n",
      "Epoch 132/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0501 - accuracy: 0.3918 - val_loss: 0.0597 - val_accuracy: 0.3469\n",
      "Epoch 133/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0500 - accuracy: 0.3977 - val_loss: 0.0599 - val_accuracy: 0.3490\n",
      "Epoch 134/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0499 - accuracy: 0.3947 - val_loss: 0.0609 - val_accuracy: 0.3483\n",
      "Epoch 135/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0501 - accuracy: 0.3981 - val_loss: 0.0601 - val_accuracy: 0.3530\n",
      "Epoch 136/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0500 - accuracy: 0.3967 - val_loss: 0.0593 - val_accuracy: 0.3478\n",
      "Epoch 137/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0500 - accuracy: 0.3967 - val_loss: 0.0601 - val_accuracy: 0.3523\n",
      "Epoch 138/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0498 - accuracy: 0.3961 - val_loss: 0.0596 - val_accuracy: 0.3548\n",
      "Epoch 139/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0500 - accuracy: 0.3963 - val_loss: 0.0598 - val_accuracy: 0.3392\n",
      "Epoch 140/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0499 - accuracy: 0.4001 - val_loss: 0.0599 - val_accuracy: 0.3587\n",
      "Epoch 141/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0498 - accuracy: 0.3960 - val_loss: 0.0609 - val_accuracy: 0.3352\n",
      "Epoch 142/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0496 - accuracy: 0.3995 - val_loss: 0.0595 - val_accuracy: 0.3401\n",
      "Epoch 143/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0496 - accuracy: 0.3984 - val_loss: 0.0598 - val_accuracy: 0.3514\n",
      "Epoch 144/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0496 - accuracy: 0.4007 - val_loss: 0.0591 - val_accuracy: 0.3360\n",
      "Epoch 145/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0499 - accuracy: 0.4020 - val_loss: 0.0598 - val_accuracy: 0.3448\n",
      "Epoch 146/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0493 - accuracy: 0.3983 - val_loss: 0.0598 - val_accuracy: 0.3481\n",
      "Epoch 147/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0495 - accuracy: 0.4019 - val_loss: 0.0606 - val_accuracy: 0.3468\n",
      "Epoch 148/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0494 - accuracy: 0.4023 - val_loss: 0.0594 - val_accuracy: 0.3551\n",
      "Epoch 149/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0494 - accuracy: 0.4026 - val_loss: 0.0601 - val_accuracy: 0.3538\n",
      "Epoch 150/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0493 - accuracy: 0.4030 - val_loss: 0.0602 - val_accuracy: 0.3467\n",
      "Epoch 151/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0493 - accuracy: 0.3982 - val_loss: 0.0597 - val_accuracy: 0.3466\n",
      "Epoch 152/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0496 - accuracy: 0.4008 - val_loss: 0.0598 - val_accuracy: 0.3461\n",
      "Epoch 153/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0492 - accuracy: 0.4066 - val_loss: 0.0593 - val_accuracy: 0.3593\n",
      "Epoch 154/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0494 - accuracy: 0.4064 - val_loss: 0.0604 - val_accuracy: 0.3593\n",
      "Epoch 155/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0496 - accuracy: 0.4032 - val_loss: 0.0597 - val_accuracy: 0.3546\n",
      "Epoch 156/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0492 - accuracy: 0.3999 - val_loss: 0.0589 - val_accuracy: 0.3582\n",
      "Epoch 157/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0494 - accuracy: 0.4001 - val_loss: 0.0593 - val_accuracy: 0.3553\n",
      "Epoch 158/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0495 - accuracy: 0.4069 - val_loss: 0.0594 - val_accuracy: 0.3502\n",
      "Epoch 159/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0493 - accuracy: 0.4069 - val_loss: 0.0590 - val_accuracy: 0.3467\n",
      "Epoch 160/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0491 - accuracy: 0.4093 - val_loss: 0.0598 - val_accuracy: 0.3667\n",
      "Epoch 161/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0490 - accuracy: 0.4026 - val_loss: 0.0598 - val_accuracy: 0.3529\n",
      "Epoch 162/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0491 - accuracy: 0.4049 - val_loss: 0.0594 - val_accuracy: 0.3534\n",
      "Epoch 163/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0490 - accuracy: 0.4047 - val_loss: 0.0595 - val_accuracy: 0.3554\n",
      "Epoch 164/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0488 - accuracy: 0.4080 - val_loss: 0.0606 - val_accuracy: 0.3522\n",
      "Epoch 165/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0488 - accuracy: 0.4078 - val_loss: 0.0594 - val_accuracy: 0.3596\n",
      "Epoch 166/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0491 - accuracy: 0.4069 - val_loss: 0.0596 - val_accuracy: 0.3598\n",
      "Epoch 167/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0490 - accuracy: 0.4077 - val_loss: 0.0596 - val_accuracy: 0.3450\n",
      "Epoch 168/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0489 - accuracy: 0.4036 - val_loss: 0.0595 - val_accuracy: 0.3652\n",
      "Epoch 169/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0488 - accuracy: 0.4051 - val_loss: 0.0589 - val_accuracy: 0.3573\n",
      "Epoch 170/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0487 - accuracy: 0.4081 - val_loss: 0.0594 - val_accuracy: 0.3593\n",
      "Epoch 171/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0486 - accuracy: 0.4070 - val_loss: 0.0602 - val_accuracy: 0.3566\n",
      "Epoch 172/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0488 - accuracy: 0.4042 - val_loss: 0.0594 - val_accuracy: 0.3556\n",
      "Epoch 173/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0488 - accuracy: 0.4072 - val_loss: 0.0591 - val_accuracy: 0.3516\n",
      "Epoch 174/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0487 - accuracy: 0.4093 - val_loss: 0.0594 - val_accuracy: 0.3551\n",
      "Epoch 175/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0486 - accuracy: 0.4050 - val_loss: 0.0595 - val_accuracy: 0.3524\n",
      "Epoch 176/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0486 - accuracy: 0.4116 - val_loss: 0.0595 - val_accuracy: 0.3638\n",
      "Epoch 177/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0487 - accuracy: 0.4089 - val_loss: 0.0595 - val_accuracy: 0.3524\n",
      "Epoch 178/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0485 - accuracy: 0.4104 - val_loss: 0.0596 - val_accuracy: 0.3536\n",
      "Epoch 179/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0484 - accuracy: 0.4088 - val_loss: 0.0594 - val_accuracy: 0.3624\n",
      "Epoch 180/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0486 - accuracy: 0.4101 - val_loss: 0.0594 - val_accuracy: 0.3506\n",
      "Epoch 181/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0485 - accuracy: 0.4112 - val_loss: 0.0595 - val_accuracy: 0.3508\n",
      "Epoch 182/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0484 - accuracy: 0.4071 - val_loss: 0.0596 - val_accuracy: 0.3667\n",
      "Epoch 183/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0485 - accuracy: 0.4111 - val_loss: 0.0592 - val_accuracy: 0.3542\n",
      "Epoch 184/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0484 - accuracy: 0.4107 - val_loss: 0.0594 - val_accuracy: 0.3481\n",
      "Epoch 185/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0484 - accuracy: 0.4060 - val_loss: 0.0592 - val_accuracy: 0.3469\n",
      "Epoch 186/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0483 - accuracy: 0.4092 - val_loss: 0.0599 - val_accuracy: 0.3591\n",
      "Epoch 187/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0483 - accuracy: 0.4092 - val_loss: 0.0600 - val_accuracy: 0.3520\n",
      "Epoch 188/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0482 - accuracy: 0.4099 - val_loss: 0.0595 - val_accuracy: 0.3506\n",
      "Epoch 189/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0484 - accuracy: 0.4112 - val_loss: 0.0601 - val_accuracy: 0.3523\n",
      "Epoch 190/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0484 - accuracy: 0.4091 - val_loss: 0.0591 - val_accuracy: 0.3520\n",
      "Epoch 191/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0483 - accuracy: 0.4115 - val_loss: 0.0596 - val_accuracy: 0.3509\n",
      "Epoch 192/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0484 - accuracy: 0.4111 - val_loss: 0.0607 - val_accuracy: 0.3556\n",
      "Epoch 193/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0482 - accuracy: 0.4106 - val_loss: 0.0594 - val_accuracy: 0.3508\n",
      "Epoch 194/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0482 - accuracy: 0.4146 - val_loss: 0.0593 - val_accuracy: 0.3472\n",
      "Epoch 195/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0481 - accuracy: 0.4091 - val_loss: 0.0594 - val_accuracy: 0.3507\n",
      "Epoch 196/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0482 - accuracy: 0.4114 - val_loss: 0.0596 - val_accuracy: 0.3531\n",
      "Epoch 197/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0481 - accuracy: 0.4091 - val_loss: 0.0594 - val_accuracy: 0.3563\n",
      "Epoch 198/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0480 - accuracy: 0.4118 - val_loss: 0.0597 - val_accuracy: 0.3512\n",
      "Epoch 199/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0478 - accuracy: 0.4162 - val_loss: 0.0591 - val_accuracy: 0.3411\n",
      "Epoch 200/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0479 - accuracy: 0.4138 - val_loss: 0.0591 - val_accuracy: 0.3464\n",
      "Epoch 201/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0479 - accuracy: 0.4143 - val_loss: 0.0596 - val_accuracy: 0.3591\n",
      "Epoch 202/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0479 - accuracy: 0.4154 - val_loss: 0.0595 - val_accuracy: 0.3536\n",
      "Epoch 203/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0479 - accuracy: 0.4129 - val_loss: 0.0596 - val_accuracy: 0.3542\n",
      "Epoch 204/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0477 - accuracy: 0.4138 - val_loss: 0.0600 - val_accuracy: 0.3634\n",
      "Epoch 205/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0482 - accuracy: 0.4111 - val_loss: 0.0594 - val_accuracy: 0.3588\n",
      "Epoch 206/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0480 - accuracy: 0.4123 - val_loss: 0.0596 - val_accuracy: 0.3621\n",
      "Epoch 207/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0477 - accuracy: 0.4140 - val_loss: 0.0595 - val_accuracy: 0.3548\n",
      "Epoch 208/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0480 - accuracy: 0.4140 - val_loss: 0.0597 - val_accuracy: 0.3527\n",
      "Epoch 209/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0479 - accuracy: 0.4114 - val_loss: 0.0590 - val_accuracy: 0.3493\n",
      "Epoch 210/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0479 - accuracy: 0.4129 - val_loss: 0.0593 - val_accuracy: 0.3564\n",
      "Epoch 211/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0477 - accuracy: 0.4156 - val_loss: 0.0592 - val_accuracy: 0.3600\n",
      "Epoch 212/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0476 - accuracy: 0.4127 - val_loss: 0.0597 - val_accuracy: 0.3548\n",
      "Epoch 213/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0475 - accuracy: 0.4143 - val_loss: 0.0596 - val_accuracy: 0.3612\n",
      "Epoch 214/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0476 - accuracy: 0.4180 - val_loss: 0.0601 - val_accuracy: 0.3491\n",
      "Epoch 215/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0477 - accuracy: 0.4139 - val_loss: 0.0592 - val_accuracy: 0.3542\n",
      "Epoch 216/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0478 - accuracy: 0.4186 - val_loss: 0.0592 - val_accuracy: 0.3651\n",
      "Epoch 217/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0477 - accuracy: 0.4135 - val_loss: 0.0592 - val_accuracy: 0.3516\n",
      "Epoch 218/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0476 - accuracy: 0.4128 - val_loss: 0.0595 - val_accuracy: 0.3567\n",
      "Epoch 219/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0476 - accuracy: 0.4147 - val_loss: 0.0586 - val_accuracy: 0.3540\n",
      "Epoch 220/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0475 - accuracy: 0.4198 - val_loss: 0.0597 - val_accuracy: 0.3511\n",
      "Epoch 221/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0475 - accuracy: 0.4203 - val_loss: 0.0593 - val_accuracy: 0.3561\n",
      "Epoch 222/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0476 - accuracy: 0.4141 - val_loss: 0.0595 - val_accuracy: 0.3549\n",
      "Epoch 223/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0475 - accuracy: 0.4144 - val_loss: 0.0589 - val_accuracy: 0.3488\n",
      "Epoch 224/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0477 - accuracy: 0.4161 - val_loss: 0.0591 - val_accuracy: 0.3552\n",
      "Epoch 225/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0476 - accuracy: 0.4159 - val_loss: 0.0589 - val_accuracy: 0.3561\n",
      "Epoch 226/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0475 - accuracy: 0.4171 - val_loss: 0.0595 - val_accuracy: 0.3520\n",
      "Epoch 227/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0475 - accuracy: 0.4143 - val_loss: 0.0592 - val_accuracy: 0.3521\n",
      "Epoch 228/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0474 - accuracy: 0.4160 - val_loss: 0.0597 - val_accuracy: 0.3548\n",
      "Epoch 229/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0474 - accuracy: 0.4169 - val_loss: 0.0590 - val_accuracy: 0.3611\n",
      "Epoch 230/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0475 - accuracy: 0.4159 - val_loss: 0.0593 - val_accuracy: 0.3520\n",
      "Epoch 231/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0473 - accuracy: 0.4156 - val_loss: 0.0597 - val_accuracy: 0.3551\n",
      "Epoch 232/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0471 - accuracy: 0.4180 - val_loss: 0.0593 - val_accuracy: 0.3544\n",
      "Epoch 233/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0472 - accuracy: 0.4233 - val_loss: 0.0590 - val_accuracy: 0.3562\n",
      "Epoch 234/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0471 - accuracy: 0.4241 - val_loss: 0.0598 - val_accuracy: 0.3599\n",
      "Epoch 235/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0475 - accuracy: 0.4188 - val_loss: 0.0600 - val_accuracy: 0.3526\n",
      "Epoch 236/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0472 - accuracy: 0.4184 - val_loss: 0.0599 - val_accuracy: 0.3521\n",
      "Epoch 237/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0474 - accuracy: 0.4152 - val_loss: 0.0590 - val_accuracy: 0.3536\n",
      "Epoch 238/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0473 - accuracy: 0.4205 - val_loss: 0.0601 - val_accuracy: 0.3566\n",
      "Epoch 239/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0472 - accuracy: 0.4176 - val_loss: 0.0589 - val_accuracy: 0.3507\n",
      "Epoch 240/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0471 - accuracy: 0.4168 - val_loss: 0.0598 - val_accuracy: 0.3610\n",
      "Epoch 241/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0473 - accuracy: 0.4197 - val_loss: 0.0599 - val_accuracy: 0.3611\n",
      "Epoch 242/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0471 - accuracy: 0.4160 - val_loss: 0.0597 - val_accuracy: 0.3506\n",
      "Epoch 243/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0473 - accuracy: 0.4207 - val_loss: 0.0592 - val_accuracy: 0.3618\n",
      "Epoch 244/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0471 - accuracy: 0.4199 - val_loss: 0.0600 - val_accuracy: 0.3487\n",
      "Epoch 245/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0473 - accuracy: 0.4206 - val_loss: 0.0588 - val_accuracy: 0.3652\n",
      "Epoch 246/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0474 - accuracy: 0.4212 - val_loss: 0.0593 - val_accuracy: 0.3537\n",
      "Epoch 247/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0472 - accuracy: 0.4211 - val_loss: 0.0588 - val_accuracy: 0.3571\n",
      "Epoch 248/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0471 - accuracy: 0.4200 - val_loss: 0.0596 - val_accuracy: 0.3403\n",
      "Epoch 249/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0471 - accuracy: 0.4190 - val_loss: 0.0590 - val_accuracy: 0.3527\n",
      "Epoch 250/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0469 - accuracy: 0.4226 - val_loss: 0.0596 - val_accuracy: 0.3594\n",
      "Epoch 251/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0471 - accuracy: 0.4225 - val_loss: 0.0590 - val_accuracy: 0.3607\n",
      "Epoch 252/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0471 - accuracy: 0.4213 - val_loss: 0.0592 - val_accuracy: 0.3528\n",
      "Epoch 253/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0470 - accuracy: 0.4238 - val_loss: 0.0591 - val_accuracy: 0.3490\n",
      "Epoch 254/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0473 - accuracy: 0.4179 - val_loss: 0.0593 - val_accuracy: 0.3590\n",
      "Epoch 255/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0472 - accuracy: 0.4198 - val_loss: 0.0589 - val_accuracy: 0.3636\n",
      "Epoch 256/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0469 - accuracy: 0.4216 - val_loss: 0.0590 - val_accuracy: 0.3544\n",
      "Epoch 257/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0470 - accuracy: 0.4221 - val_loss: 0.0593 - val_accuracy: 0.3683\n",
      "Epoch 258/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0471 - accuracy: 0.4234 - val_loss: 0.0600 - val_accuracy: 0.3553\n",
      "Epoch 259/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0466 - accuracy: 0.4212 - val_loss: 0.0590 - val_accuracy: 0.3630\n",
      "Epoch 260/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0468 - accuracy: 0.4241 - val_loss: 0.0592 - val_accuracy: 0.3554\n",
      "Epoch 261/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0469 - accuracy: 0.4183 - val_loss: 0.0585 - val_accuracy: 0.3573\n",
      "Epoch 262/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0467 - accuracy: 0.4273 - val_loss: 0.0593 - val_accuracy: 0.3652\n",
      "Epoch 263/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0469 - accuracy: 0.4227 - val_loss: 0.0593 - val_accuracy: 0.3538\n",
      "Epoch 264/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0469 - accuracy: 0.4200 - val_loss: 0.0589 - val_accuracy: 0.3620\n",
      "Epoch 265/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0469 - accuracy: 0.4253 - val_loss: 0.0594 - val_accuracy: 0.3593\n",
      "Epoch 266/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0470 - accuracy: 0.4177 - val_loss: 0.0595 - val_accuracy: 0.3568\n",
      "Epoch 267/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0469 - accuracy: 0.4251 - val_loss: 0.0596 - val_accuracy: 0.3572\n",
      "Epoch 268/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0468 - accuracy: 0.4224 - val_loss: 0.0595 - val_accuracy: 0.3656\n",
      "Epoch 269/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0469 - accuracy: 0.4196 - val_loss: 0.0593 - val_accuracy: 0.3637\n",
      "Epoch 270/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0467 - accuracy: 0.4209 - val_loss: 0.0591 - val_accuracy: 0.3630\n",
      "Epoch 271/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0465 - accuracy: 0.4194 - val_loss: 0.0589 - val_accuracy: 0.3556\n",
      "Epoch 272/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0467 - accuracy: 0.4237 - val_loss: 0.0594 - val_accuracy: 0.3501\n",
      "Epoch 273/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0467 - accuracy: 0.4188 - val_loss: 0.0591 - val_accuracy: 0.3567\n",
      "Epoch 274/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0468 - accuracy: 0.4261 - val_loss: 0.0590 - val_accuracy: 0.3537\n",
      "Epoch 275/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0467 - accuracy: 0.4190 - val_loss: 0.0594 - val_accuracy: 0.3620\n",
      "Epoch 276/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0468 - accuracy: 0.4255 - val_loss: 0.0594 - val_accuracy: 0.3637\n",
      "Epoch 277/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0466 - accuracy: 0.4211 - val_loss: 0.0592 - val_accuracy: 0.3679\n",
      "Epoch 278/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0467 - accuracy: 0.4254 - val_loss: 0.0587 - val_accuracy: 0.3571\n",
      "Epoch 279/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0464 - accuracy: 0.4276 - val_loss: 0.0596 - val_accuracy: 0.3596\n",
      "Epoch 280/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0464 - accuracy: 0.4236 - val_loss: 0.0594 - val_accuracy: 0.3582\n",
      "Epoch 281/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0466 - accuracy: 0.4257 - val_loss: 0.0596 - val_accuracy: 0.3441\n",
      "Epoch 282/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0465 - accuracy: 0.4240 - val_loss: 0.0594 - val_accuracy: 0.3586\n",
      "Epoch 283/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0466 - accuracy: 0.4228 - val_loss: 0.0600 - val_accuracy: 0.3634\n",
      "Epoch 284/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0467 - accuracy: 0.4263 - val_loss: 0.0588 - val_accuracy: 0.3619\n",
      "Epoch 285/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0462 - accuracy: 0.4234 - val_loss: 0.0605 - val_accuracy: 0.3612\n",
      "Epoch 286/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0465 - accuracy: 0.4267 - val_loss: 0.0594 - val_accuracy: 0.3590\n",
      "Epoch 287/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0466 - accuracy: 0.4257 - val_loss: 0.0588 - val_accuracy: 0.3638\n",
      "Epoch 288/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0466 - accuracy: 0.4264 - val_loss: 0.0588 - val_accuracy: 0.3621\n",
      "Epoch 289/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0465 - accuracy: 0.4233 - val_loss: 0.0586 - val_accuracy: 0.3563\n",
      "Epoch 290/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0463 - accuracy: 0.4273 - val_loss: 0.0586 - val_accuracy: 0.3603\n",
      "Epoch 291/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0464 - accuracy: 0.4236 - val_loss: 0.0594 - val_accuracy: 0.3492\n",
      "Epoch 292/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0464 - accuracy: 0.4251 - val_loss: 0.0598 - val_accuracy: 0.3637\n",
      "Epoch 293/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0465 - accuracy: 0.4263 - val_loss: 0.0590 - val_accuracy: 0.3607\n",
      "Epoch 294/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0463 - accuracy: 0.4224 - val_loss: 0.0591 - val_accuracy: 0.3597\n",
      "Epoch 295/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0464 - accuracy: 0.4230 - val_loss: 0.0591 - val_accuracy: 0.3572\n",
      "Epoch 296/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0463 - accuracy: 0.4262 - val_loss: 0.0596 - val_accuracy: 0.3601\n",
      "Epoch 297/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0465 - accuracy: 0.4232 - val_loss: 0.0589 - val_accuracy: 0.3641\n",
      "Epoch 298/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0462 - accuracy: 0.4277 - val_loss: 0.0588 - val_accuracy: 0.3549\n",
      "Epoch 299/300\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0466 - accuracy: 0.4310 - val_loss: 0.0599 - val_accuracy: 0.3580\n",
      "Epoch 300/300\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0463 - accuracy: 0.4274 - val_loss: 0.0586 - val_accuracy: 0.3621\n",
      "Elapsed time is 982.9841849803925 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "982.9841849803925"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_loss = CustomLoss(loss_functions)\n",
    "model = create_model(model_name, input_shape, custom_loss.custom_loss)\n",
    "\n",
    "tic()\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    # pass validtation for monitoring\n",
    "                    # validation loss and metrics\n",
    "                    validation_data=(x_validation, y_validation))\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8304582645634393"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(model.predict(x_validation), y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04554226, 0.13161794, 0.19970727, ..., 0.50869141, 0.4630841 ,\n",
       "        0.43334177],\n",
       "       [0.02387373, 0.05302663, 0.08701167, ..., 0.16515124, 0.15117632,\n",
       "        0.14401359],\n",
       "       [0.08229554, 0.28669726, 0.36861696, ..., 0.64594702, 0.62050522,\n",
       "        0.60189368],\n",
       "       ...,\n",
       "       [0.11900184, 0.24443641, 0.41585053, ..., 0.70286582, 0.70835893,\n",
       "        0.71002132],\n",
       "       [0.1400889 , 0.29418886, 0.31678291, ..., 0.67493043, 0.67091901,\n",
       "        0.65100647],\n",
       "       [0.05870406, 0.17402335, 0.18622023, ..., 0.49969282, 0.46228904,\n",
       "        0.44382205]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianProcessRegressor(alpha=1e-10, copy_X_train=True, kernel=None,\n",
       "                         n_restarts_optimizer=0, normalize_y=False,\n",
       "                         optimizer='fmin_l_bfgs_b', random_state=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPR = GaussianProcessRegressor()\n",
    "GPR.fit(model.predict(x_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7291968004355268"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPR.score(model.predict(x_validation), y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13799512, 0.24049854, 0.27672076, ..., 0.69531256, 0.68968546,\n",
       "        0.68625379],\n",
       "       [0.07714093, 0.22534847, 0.26344371, ..., 0.58214211, 0.57711148,\n",
       "        0.57322097],\n",
       "       [0.07667208, 0.20028722, 0.3048892 , ..., 0.66256994, 0.62811518,\n",
       "        0.60188019],\n",
       "       ...,\n",
       "       [0.20464897, 0.35903203, 0.49649644, ..., 0.80287451, 0.79860353,\n",
       "        0.79136992],\n",
       "       [0.10273278, 0.22671139, 0.35660434, ..., 0.58054662, 0.58338797,\n",
       "        0.57260323],\n",
       "       [0.17588353, 0.22008109, 0.32180977, ..., 0.62356079, 0.62931049,\n",
       "        0.62598681]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPR.predict(model.predict(x_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9000, 24), (9000, 24))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict(x_validation).shape, y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./models/GPR_300_elu.pkl'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'./models/GPR_{epochs}_{activation}.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/GPR_300_elu.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(GPR, f'./models/GPR_{epochs}_{activation}.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.029757313430309296\n",
      "Train accuracy: 0.5111481547355652\n",
      "accuracy: 51.11%\n",
      "Saved model to disk\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1])\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1] * 100))\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "model_export_path_folder = 'models/{}_{}_{}_{}'.format(model_name, batch_size, epochs, activation)\n",
    "if not os.path.exists(model_export_path_folder):\n",
    "    os.makedirs(model_export_path_folder)\n",
    "\n",
    "model_export_path_template = '{}/{}_{}_1.{}'\n",
    "model_export_path = model_export_path_template.format(model_export_path_folder, loss_functions,\n",
    "                                                        input_shape_type, 'json')\n",
    "with open(model_export_path, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\n",
    "    model_export_path_template.format(model_export_path_folder, loss_functions, input_shape_type, 'h5'))\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "# Loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Model - Loss')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "train_progress_figure_path_folder = 'result/train_progress'\n",
    "if not os.path.exists(train_progress_figure_path_folder):\n",
    "    os.makedirs(train_progress_figure_path_folder)\n",
    "plt.savefig('{}/{}_{}.png'.format(train_progress_figure_path_folder, model_name, loss_functions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
